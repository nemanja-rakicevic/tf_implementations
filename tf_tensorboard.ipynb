{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE A SIMPLE NEURAL NETWORK\n",
    "\n",
    "# learning parameters\n",
    "lr = 0.001\n",
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "disp_step = 1\n",
    "model_path = \"./model_data/nn_model.ckpt\"\n",
    "logs_path = './logs_data/example/'\n",
    "\n",
    "# network parameters\n",
    "n_input = 784\n",
    "n_hidd1 = 256\n",
    "n_hidd2 = 128\n",
    "n_out   = 10\n",
    "\n",
    "# inputs\n",
    "X = tf.placeholder(tf.float32, [None, n_input], name='input_data')\n",
    "Y = tf.placeholder(tf.float32, [None, n_out], name='output_prediction')\n",
    "\n",
    "# Weights\n",
    "weights = {\n",
    "    'w1': tf.Variable(tf.random_normal([n_input, n_hidd1]), name='w1'),\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidd1]), name='b1'),\n",
    "    'w2': tf.Variable(tf.random_normal([n_hidd1, n_hidd2]), name='w2'),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidd2]), name='b2'),\n",
    "    'wout': tf.Variable(tf.random_normal([n_hidd2, n_out]), name='wout'),\n",
    "    'bout': tf.Variable(tf.random_normal([n_out]), name='bout'),\n",
    "}\n",
    "\n",
    "# Model\n",
    "def multilayer_perceptron(x, weights):\n",
    "    lay1 = tf.add(tf.matmul(x, weights['w1']), weights['b1'])\n",
    "    lay1 = tf.nn.relu(lay1)\n",
    "    lay2 = tf.add(tf.matmul(lay1, weights['w2']), weights['b2'])\n",
    "    lay2 = tf.nn.relu(lay2)\n",
    "    lay_out = tf.add(tf.matmul(lay2, weights['wout']), weights['bout'])\n",
    "    return lay_out\n",
    " \n",
    "with tf.name_scope('Model'):\n",
    "    prediction = multilayer_perceptron(X, weights)\n",
    "    \n",
    "# Cost\n",
    "with tf.name_scope('Loss'):\n",
    "    op_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "                                logits=prediction, labels=Y))\n",
    "\n",
    "# Optimisation\n",
    "with tf.name_scope('Optimiser'):\n",
    "    op_optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(op_cost)\n",
    "    # op to apply gradients\n",
    "    op_grads = tf.gradients(op_cost, tf.trainable_variables())\n",
    "    op_grads = list(zip(op_grads, tf.trainable_variables()))\n",
    "    \n",
    "\n",
    "# Evaluation \n",
    "with tf.name_scope('Accuracy'):\n",
    "    correct = tf.equal(tf.argmax(prediction,1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "# Init\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name w1:0 is illegal; using w1_0 instead.\n",
      "INFO:tensorflow:Summary name b1:0 is illegal; using b1_0 instead.\n",
      "INFO:tensorflow:Summary name w2:0 is illegal; using w2_0 instead.\n",
      "INFO:tensorflow:Summary name b2:0 is illegal; using b2_0 instead.\n",
      "INFO:tensorflow:Summary name wout:0 is illegal; using wout_0 instead.\n",
      "INFO:tensorflow:Summary name bout:0 is illegal; using bout_0 instead.\n",
      "INFO:tensorflow:Summary name w1:0/gradient is illegal; using w1_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b1:0/gradient is illegal; using b1_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w2:0/gradient is illegal; using w2_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b2:0/gradient is illegal; using b2_0/gradient instead.\n",
      "INFO:tensorflow:Summary name wout:0/gradient is illegal; using wout_0/gradient instead.\n",
      "INFO:tensorflow:Summary name bout:0/gradient is illegal; using bout_0/gradient instead.\n"
     ]
    }
   ],
   "source": [
    "# INITIALISE MODEL \"SAVER\"\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# INITIALISE MODEL \"SUMMARY\" for Tensorboard\n",
    "# cost tensor\n",
    "tf.summary.scalar(\"loss\", op_cost)\n",
    "# accuracy tensor\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "# gradients\n",
    "for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.name, var)\n",
    "for grad, var in op_grads:\n",
    "    tf.summary.histogram(var.name + '/gradient', grad)\n",
    "\n",
    "# Merge all summaries into a single op\n",
    "op_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1st session...\n",
      "Epoch: 0001 cost= 145.968365218\n",
      "Epoch: 0002 cost= 29.978168872\n",
      "Epoch: 0003 cost= 19.050126300\n",
      "Epoch: 0004 cost= 13.778274806\n",
      "Epoch: 0005 cost= 10.319705743\n",
      "First Optimization Finished!\n",
      "Accuracy: 0.9207\n",
      "Model saved in:  ./model_data/nn_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "num_batches = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "# Start Session #1\n",
    "print \"Starting 1st session...\"\n",
    "\n",
    "with tf.Session() as s1:\n",
    "    s1.run(init)\n",
    "    \n",
    "    for e in range(5):\n",
    "        avg_cost = 0.\n",
    "        for b in range(num_batches):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, loss = s1.run([op_optimizer, op_cost], feed_dict={X: batch_xs,\\\n",
    "                                                                 Y: batch_ys})\n",
    "            avg_cost += loss/num_batches\n",
    "            \n",
    "        if e%disp_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (e+1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "        \n",
    "    # DONE FIRST PART\n",
    "    print \"First Optimization Finished!\"\n",
    "    print \"Accuracy:\", accuracy.eval({X: mnist.test.images, Y: mnist.test.labels})\n",
    "    \n",
    "    # SAVE CURRENT MODEL\n",
    "    save_path = saver.save(s1, model_path)\n",
    "    print \"Model saved in: \", save_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 2nd session...\n",
      "INFO:tensorflow:Restoring parameters from ./model_data/nn_model.ckpt\n",
      "Model restored from: None\n",
      "Epoch: 0001 cost= 8.046402465\n",
      "Epoch: 0002 cost= 6.243569126\n",
      "Epoch: 0003 cost= 4.826823533\n",
      "Epoch: 0004 cost= 3.708817050\n",
      "Epoch: 0005 cost= 2.901680179\n",
      "Epoch: 0006 cost= 2.311864388\n",
      "Epoch: 0007 cost= 1.727156266\n",
      "Epoch: 0008 cost= 1.365209522\n",
      "Epoch: 0009 cost= 1.048879909\n",
      "Epoch: 0010 cost= 0.791116597\n",
      "Second Optimization Finished!\n",
      "Accuracy: 0.9431\n",
      "Run the command line:\n",
      "--> tensorboard --logdir=./logs_data \n",
      "Then open http://0.0.0.0:6006/ into your web browser\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Start Session #2\n",
    "print \"Starting 2nd session...\"\n",
    "\n",
    "with tf.Session() as s1:\n",
    "    s1.run(init)\n",
    "    \n",
    "    load_path = saver.restore(s1, model_path)\n",
    "    print \"Model restored from:\", load_path\n",
    "    \n",
    "    \n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    \n",
    "    # resume training\n",
    "    for e in range(num_epochs):\n",
    "        avg_cost = 0.\n",
    "        for b in range(num_batches):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, loss, summary = s1.run([op_optimizer, op_cost, op_summary], feed_dict={X: batch_xs,\\\n",
    "                                                                 Y: batch_ys})\n",
    "            avg_cost += loss/num_batches\n",
    "            \n",
    "            # Write logs at every iteration\n",
    "            summary_writer.add_summary(summary, e * num_batches + b)\n",
    "            \n",
    "            \n",
    "        if e%disp_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (e+1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "        \n",
    "    # DONE SECOND PART\n",
    "    print \"Second Optimization Finished!\"\n",
    "    print \"Accuracy:\", accuracy.eval({X: mnist.test.images, Y: mnist.test.labels})\n",
    "    \n",
    "    \n",
    "    print \"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=./logs_data \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\"\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
